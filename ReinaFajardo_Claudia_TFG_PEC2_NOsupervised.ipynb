{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRABAJO FINAL DE GRADO - PEC 2\n",
    "###### Autor: Claudia Reina Fajardo\n",
    "###### Noviembre 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de aprendizaje no supervisado: K-Means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos el dataset\n",
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means sobre depresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "| CALIDAD DEL MODELO |\n",
      "======================\n",
      " - Precisión               : 72.01761409127302%\n",
      "\n",
      "==============================\n",
      "| RESULTADO DE LA PREDICCIÓN |\n",
      "==============================\n",
      " - Datos sin clasificar        : [ 1.  49.   6.   2.   2.   1.   4.   2.   0.   0.   3.4  2.   1.   2.\n",
      "  2.   2.   2.   2.   2.   2.   2.   0.   0.   0.   0.   1.   0.   0.\n",
      "  0.   2.   2.   1.   1.   3.   0.   2.   2.   2.   2.   2.   2.   2.\n",
      "  2.   2.   2.   2.   2.   2.   2.   2.   2.   2.   2.   2.   2.   2.\n",
      "  1.   0.   1.   2.   2.   2.   3.   9.   9.   9.   9.   5. ]\n",
      " - Clasificación        : 0\n",
      "\n",
      " - Datos sin clasificar        : [ 2.   63.    6.    2.    2.    1.    4.    1.    0.    2.    2.73  1.\n",
      "  2.    2.    2.    2.    2.    1.    1.    2.    1.    3.    0.    0.\n",
      "  0.    0.    0.    0.    0.    2.    2.    2.    4.    2.    0.    2.\n",
      "  2.    2.    2.    2.    2.    2.    2.    2.    2.    2.    2.    2.\n",
      "  2.    2.    2.    2.    2.    2.    1.    1.    1.    8.    8.    2.\n",
      "  2.    2.    2.    9.    9.    9.    9.    1.  ]\n",
      " - Clasificación        : 0\n",
      "\n",
      " - Datos sin clasificar        : [ 2.   80.    1.    2.    2.    2.    4.    0.    1.    1.    2.76  2.\n",
      "  2.    2.    3.    2.    2.    1.    1.    1.    1.    0.    0.    3.\n",
      "  0.    9.    0.    0.    1.    2.    2.    1.    2.    3.    0.    2.\n",
      "  2.    2.    1.    2.    1.    2.    2.    2.    2.    2.    2.    2.\n",
      "  2.    2.    2.    2.    2.    2.    2.    2.    4.    4.    8.    2.\n",
      "  2.    2.    2.    9.    9.    9.    9.    2.  ]\n",
      " - Clasificación        : 0\n",
      "\n",
      " - Datos sin clasificar        : [ 1.   80.    2.    2.    2.    1.    3.    0.    1.    2.    1.54  2.\n",
      "  2.    2.    3.    1.    2.    1.    2.    2.    1.    9.    1.    0.\n",
      "  0.    0.    9.    0.    0.    2.    2.    1.    4.    1.    0.    2.\n",
      "  2.    2.    2.    2.    2.    2.    2.    2.    2.    2.    2.    2.\n",
      "  2.    2.    2.    2.    2.    2.    2.    1.    4.    0.    8.    1.\n",
      "  2.    1.    3.    9.    9.    9.    9.    2.  ]\n",
      " - Clasificación        : 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# plantamos semilla para que nos de el mismo resultado en las diferentes ejecuciones\n",
    "np.random.seed(0)\n",
    "\n",
    "# eliminamos la clase del conjunto de datos y los elementos sin clasificar y la guardamos para comprobar precisión\n",
    "data=df[df.depressed<2]\n",
    "clase=data.depressed\n",
    "data=data.drop(['depressed'], axis=1).values\n",
    "\n",
    "# estandarizamos los datos\n",
    "media=np.mean(data,0)\n",
    "desv=np.std(data,0)\n",
    "data=np.divide((data-media),desv)\n",
    "\n",
    "# aplicamos K-Means con 2 clústers, ya que queremos clasificar el conjunto de forma binaria\n",
    "kMeans=KMeans(n_clusters=2,max_iter=25).fit(data)\n",
    "\n",
    "# calculamos los aciertos comparando las etiquetas con la clase\n",
    "aciertos=np.count_nonzero((kMeans.labels_-clase)==0)\n",
    "total=len(kMeans.labels_)\n",
    "\n",
    "# calculamos precisión dividiendo aciertos entre total de estimaciones\n",
    "prec=float(aciertos)/float(total)\n",
    "print('======================')\n",
    "print('| CALIDAD DEL MODELO |')\n",
    "print('======================')\n",
    "print(' - Precisión               : '+str(100*prec)+'%')\n",
    "print('')\n",
    "# probamos con aquellos valores que no se habían clasificado\n",
    "prob=df[df.depressed>1]\n",
    "prob=prob.drop(['depressed'], axis=1).values\n",
    "\n",
    "# predicción\n",
    "new = kMeans.predict(data)\n",
    "print('==============================')\n",
    "print('| RESULTADO DE LA PREDICCIÓN |')\n",
    "print('==============================')\n",
    "# resultados\n",
    "for i in range(prob.shape[0]):\n",
    "    print(' - Datos sin clasificar        : '+str(prob[i,:]))\n",
    "    print(' - Clasificación        : '+str(new[i]))\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means sobre pensamientos de muerte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "| CALIDAD DEL MODELO |\n",
      "======================\n",
      " - Precisión               : 91.09643857543017%\n",
      "\n",
      "==============================\n",
      "| RESULTADO DE LA PREDICCIÓN |\n",
      "==============================\n",
      " - Datos sin clasificar        : [ 2.   61.    3.    2.    1.    2.    4.    1.    1.    1.    1.23  1.\n",
      "  1.    1.    3.    1.    2.    1.    1.    1.    1.    3.    1.    1.\n",
      "  3.    3.    0.    0.    0.    2.    2.    1.    5.    2.    0.    2.\n",
      "  2.    2.    2.    2.    2.    2.    1.    2.    1.    2.    2.    1.\n",
      "  1.    2.    2.    1.    2.    1.    2.    2.    4.    5.    5.    2.\n",
      "  2.    1.    3.    9.    9.    9.    9.    2.  ]\n",
      " - Clasificación        : 0\n",
      "\n",
      " - Datos sin clasificar        : [ 1.   54.    1.    2.    1.    3.    3.    0.    0.    2.    0.77  1.\n",
      "  2.    2.    3.    2.    2.    2.    2.    2.    2.    3.    1.    1.\n",
      "  3.    0.    1.    0.    1.    2.    2.    2.    4.    3.    0.    2.\n",
      "  2.    2.    1.    2.    2.    2.    2.    2.    2.    2.    2.    2.\n",
      "  2.    2.    2.    2.    2.    2.    1.    1.    4.    3.    1.    2.\n",
      "  2.    1.    2.   10.   13.    9.    9.    3.  ]\n",
      " - Clasificación        : 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# plantamos semilla para que nos de el mismo resultado en las diferentes ejecuciones\n",
    "np.random.seed(0)\n",
    "\n",
    "# eliminamos la clase del conjunto de datos y los elementos sin clasificar y la guardamos para comprobar precisión\n",
    "data=df[df.dead<2]\n",
    "clase=data.dead\n",
    "data=data.drop(['dead'], axis=1).values\n",
    "\n",
    "# estandarizamos los datos\n",
    "media=np.mean(data,0)\n",
    "desv=np.std(data,0)\n",
    "data=np.divide((data-media),desv)\n",
    "\n",
    "# aplicamos K-Means con 2 clústers, ya que queremos clasificar el conjunto de forma binaria\n",
    "kMeans=KMeans(n_clusters=2,max_iter=25).fit(data)\n",
    "\n",
    "# calculamos los aciertos comparando las etiquetas con la clase\n",
    "aciertos=np.count_nonzero((kMeans.labels_-clase)==0)\n",
    "total=len(kMeans.labels_)\n",
    "\n",
    "# calculamos precisión dividiendo aciertos entre total de estimaciones\n",
    "prec=float(aciertos)/float(total)\n",
    "print('======================')\n",
    "print('| CALIDAD DEL MODELO |')\n",
    "print('======================')\n",
    "print(' - Precisión               : '+str(100*prec)+'%')\n",
    "print('')\n",
    "# probamos con aquellos valores que no se habían clasificado\n",
    "prob=df[df.dead>1]\n",
    "prob=prob.drop(['dead'], axis=1).values\n",
    "\n",
    "# predicción\n",
    "new = kMeans.predict(data)\n",
    "print('==============================')\n",
    "print('| RESULTADO DE LA PREDICCIÓN |')\n",
    "print('==============================')\n",
    "# resultados\n",
    "for i in range(prob.shape[0]):\n",
    "    print(' - Datos sin clasificar        : '+str(prob[i,:]))\n",
    "    print(' - Clasificación        : '+str(new[i]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means sobre insomnio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "| CALIDAD DEL MODELO |\n",
      "======================\n",
      " - Precisión               : 61.97239447889578%\n",
      "\n",
      "==============================\n",
      "| RESULTADO DE LA PREDICCIÓN |\n",
      "==============================\n",
      " - Datos sin clasificar        : [ 2.   74.    2.    2.    1.    1.    3.    0.    0.    2.    0.77  1.\n",
      "  2.    2.    3.    2.    1.    2.    2.    2.    2.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    2.    2.    1.    3.    3.    0.    2.\n",
      "  2.    2.    2.    2.    1.    2.    2.    2.    2.    2.    2.    2.\n",
      "  1.    2.    2.    2.    2.    1.    1.    1.    4.    5.    0.    2.\n",
      "  2.    1.    2.    9.    9.    9.    9.    3.  ]\n",
      " - Clasificación        : 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# plantamos semilla para que nos de el mismo resultado en las diferentes ejecuciones\n",
    "np.random.seed(0)\n",
    "\n",
    "# eliminamos la clase del conjunto de datos y los elementos sin clasificar y la guardamos para comprobar precisión\n",
    "data=df[df.sleep<2]\n",
    "clase=data.sleep\n",
    "data=data.drop(['sleep'], axis=1).values\n",
    "\n",
    "# estandarizamos los datos\n",
    "media=np.mean(data,0)\n",
    "desv=np.std(data,0)\n",
    "data=np.divide((data-media),desv)\n",
    "\n",
    "# aplicamos K-Means con 2 clústers, ya que queremos clasificar el conjunto de forma binaria\n",
    "kMeans=KMeans(n_clusters=2,max_iter=25).fit(data)\n",
    "\n",
    "# calculamos los aciertos comparando las etiquetas con la clase\n",
    "aciertos=np.count_nonzero((kMeans.labels_-clase)==0)\n",
    "total=len(kMeans.labels_)\n",
    "\n",
    "# calculamos precisión dividiendo aciertos entre total de estimaciones\n",
    "prec=float(aciertos)/float(total)\n",
    "print('======================')\n",
    "print('| CALIDAD DEL MODELO |')\n",
    "print('======================')\n",
    "print(' - Precisión               : '+str(100*prec)+'%')\n",
    "print('')\n",
    "# probamos con aquellos valores que no se habían clasificado\n",
    "prob=df[df.sleep>1]\n",
    "prob=prob.drop(['sleep'], axis=1).values\n",
    "\n",
    "# predicción\n",
    "new = kMeans.predict(data)\n",
    "print('==============================')\n",
    "print('| RESULTADO DE LA PREDICCIÓN |')\n",
    "print('==============================')\n",
    "# resultados\n",
    "for i in range(prob.shape[0]):\n",
    "    print(' - Datos sin clasificar        : '+str(prob[i,:]))\n",
    "    print(' - Clasificación        : '+str(new[i]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means sobre autoestima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "| CALIDAD DEL MODELO |\n",
      "======================\n",
      " - Precisión               : 78.77150860344138%\n",
      "\n",
      "==============================\n",
      "| RESULTADO DE LA PREDICCIÓN |\n",
      "==============================\n",
      " - Datos sin clasificar        : [ 2. 80.  3.  2.  1.  1.  2.  0.  0.  2.  5.  1.  1.  2.  3.  2.  2.  2.\n",
      "  1.  1.  2.  0.  0.  0.  0.  0.  0.  0.  0.  2.  2.  1.  4.  3.  0.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  4.  2.  1.  2.  2.  2.  3. 10.  9.  9.  9.  4.]\n",
      " - Clasificación        : 0\n",
      "\n",
      " - Datos sin clasificar        : [ 2.   80.    1.    2.    2.    2.    4.    0.    1.    1.    2.76  2.\n",
      "  2.    2.    3.    2.    2.    1.    1.    1.    1.    0.    9.    0.\n",
      "  3.    0.    0.    0.    1.    2.    2.    1.    2.    3.    0.    2.\n",
      "  2.    2.    1.    2.    1.    2.    2.    2.    2.    2.    2.    2.\n",
      "  2.    2.    2.    2.    2.    2.    2.    2.    4.    4.    8.    2.\n",
      "  2.    2.    2.    9.    9.    9.    9.    2.  ]\n",
      " - Clasificación        : 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# plantamos semilla para que nos de el mismo resultado en las diferentes ejecuciones\n",
    "np.random.seed(0)\n",
    "\n",
    "# eliminamos la clase del conjunto de datos y los elementos sin clasificar y la guardamos para comprobar precisión\n",
    "data=df[df.yourself<2]\n",
    "clase=data.yourself\n",
    "data=data.drop(['yourself'], axis=1).values\n",
    "\n",
    "# estandarizamos los datos\n",
    "media=np.mean(data,0)\n",
    "desv=np.std(data,0)\n",
    "data=np.divide((data-media),desv)\n",
    "\n",
    "# aplicamos K-Means con 2 clústers, ya que queremos clasificar el conjunto de forma binaria\n",
    "kMeans=KMeans(n_clusters=2,max_iter=25).fit(data)\n",
    "\n",
    "# calculamos los aciertos comparando las etiquetas con la clase\n",
    "aciertos=np.count_nonzero((kMeans.labels_-clase)==0)\n",
    "total=len(kMeans.labels_)\n",
    "\n",
    "# calculamos precisión dividiendo aciertos entre total de estimaciones\n",
    "prec=float(aciertos)/float(total)\n",
    "print('======================')\n",
    "print('| CALIDAD DEL MODELO |')\n",
    "print('======================')\n",
    "print(' - Precisión               : '+str(100*prec)+'%')\n",
    "print('')\n",
    "# probamos con aquellos valores que no se habían clasificado\n",
    "prob=df[df.yourself>1]\n",
    "prob=prob.drop(['yourself'], axis=1).values\n",
    "\n",
    "# predicción\n",
    "new = kMeans.predict(data)\n",
    "print('==============================')\n",
    "print('| RESULTADO DE LA PREDICCIÓN |')\n",
    "print('==============================')\n",
    "# resultados\n",
    "for i in range(prob.shape[0]):\n",
    "    print(' - Datos sin clasificar        : '+str(prob[i,:]))\n",
    "    print(' - Clasificación        : '+str(new[i]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means sobre visita en salud mental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================\n",
      "| CALIDAD DEL MODELO |\n",
      "======================\n",
      " - Precisión               : 86.41184710826496%\n",
      "\n",
      "==============================\n",
      "| RESULTADO DE LA PREDICCIÓN |\n",
      "==============================\n",
      " - Datos sin clasificar        : [ 2.   68.    6.    2.    2.    1.    5.    1.    0.    2.    0.86  2.\n",
      "  9.    1.    3.    1.    2.    2.    1.    2.    1.    0.    0.    1.\n",
      "  1.    0.    0.    0.    0.    0.    2.    2.    1.    5.    1.    2.\n",
      "  2.    2.    2.    2.    2.    2.    2.    2.    2.    2.    2.    2.\n",
      "  2.    2.    2.    2.    2.    2.    2.    2.    4.    1.    8.    2.\n",
      "  2.    2.    3.    9.    9.    9.    9.    1.  ]\n",
      " - Clasificación        : 0\n",
      "\n",
      " - Datos sin clasificar        : [ 1.   47.    3.    2.    2.    3.    1.    0.    0.    0.    3.26  1.\n",
      "  1.    2.    3.    2.    2.    2.    2.    2.    2.    0.    0.    0.\n",
      "  1.    1.    1.    0.    0.    0.    2.    2.    1.    3.    2.    2.\n",
      "  2.    2.    1.    2.    2.    2.    2.    2.    2.    2.    2.    2.\n",
      "  2.    2.    1.    2.    2.    2.    1.    1.    1.    3.    1.    2.\n",
      "  1.    1.    2.    9.   13.    9.    9.    3.  ]\n",
      " - Clasificación        : 0\n",
      "\n",
      " - Datos sin clasificar        : [ 1.   18.    6.    2.    1.    5.    3.    0.    0.    0.    3.03  2.\n",
      "  2.    2.    2.    2.    2.    2.    2.    2.    2.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    2.    2.    1.    2.    1.    2.\n",
      "  2.    2.    2.    2.    9.    9.    9.    9.    9.    9.    9.    9.\n",
      "  9.    9.    9.    9.    2.    9.    1.    1.    1.    2.    8.    2.\n",
      "  2.    2.    2.    9.   13.    9.    9.    3.  ]\n",
      " - Clasificación        : 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# plantamos semilla para que nos de el mismo resultado en las diferentes ejecuciones\n",
    "np.random.seed(0)\n",
    "\n",
    "# eliminamos la clase del conjunto de datos y los elementos sin clasificar y la guardamos para comprobar precisión\n",
    "data=df[df.profMental<2]\n",
    "clase=data.profMental\n",
    "data=data.drop(['profMental'], axis=1).values\n",
    "\n",
    "# estandarizamos los datos\n",
    "media=np.mean(data,0)\n",
    "desv=np.std(data,0)\n",
    "data=np.divide((data-media),desv)\n",
    "\n",
    "# aplicamos K-Means con 2 clústers, ya que queremos clasificar el conjunto de forma binaria\n",
    "kMeans=KMeans(n_clusters=2,max_iter=25).fit(data)\n",
    "\n",
    "# calculamos los aciertos comparando las etiquetas con la clase\n",
    "aciertos=np.count_nonzero((kMeans.labels_-clase)==0)\n",
    "total=len(kMeans.labels_)\n",
    "\n",
    "# calculamos precisión dividiendo aciertos entre total de estimaciones\n",
    "prec=float(aciertos)/float(total)\n",
    "print('======================')\n",
    "print('| CALIDAD DEL MODELO |')\n",
    "print('======================')\n",
    "print(' - Precisión               : '+str(100*prec)+'%')\n",
    "print('')\n",
    "# probamos con aquellos valores que no se habían clasificado\n",
    "prob=df[df.profMental>1]\n",
    "prob=prob.drop(['profMental'], axis=1).values\n",
    "\n",
    "# predicción\n",
    "new = kMeans.predict(data)\n",
    "print('==============================')\n",
    "print('| RESULTADO DE LA PREDICCIÓN |')\n",
    "print('==============================')\n",
    "# resultados\n",
    "for i in range(prob.shape[0]):\n",
    "    print(' - Datos sin clasificar        : '+str(prob[i,:]))\n",
    "    print(' - Clasificación        : '+str(new[i]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
